\title{The Skew-Normal Approximation of the Binomial Distribution}
\author{Joyce Tipping}
\date{2010}
\maketitle

\section{Introduction}

One of the most basic distributions in statistics is the binomial, $X \sim
Bin(n,p)$, $n \in \N$, $p \in (0, 1)$ with probability density function (pdf)

\begin{equation*}
  f_X(x) = \binom{n}{x} p^x q^{n-x}, \quad x = 0, 1, \ldots, n,
\end{equation*}

where $q=1-p$. Calculating the binomial cumulative distribution function (cdf),
$F_X(x) = P(X \leq x) = \sum_{k=1}^x f_X(k)$, by hand is manageable for small
$n$ but quickly becomes cumbersome as $n$ grows even moderately large. A common
strategy is to use the normal distribution\footnote{A random variable $X$
follows the normal distribution with mean $\mu$ and variance $\sigma^2$ if it
has the pdf

\begin{equation*}
  f(x;\mu,\sigma) = \frac{1}{\sqrt{2\pi}\,\sigma} \; e^{-[(x-\mu)/\sigma]^2/2}
\end{equation*}

for $-\infty < x < \infty$, where $-\infty < \mu < \infty$ and $0 < \sigma <
\infty$. This is denoted by $X \sim N(\mu,\sigma^2)$.\\

$N(0,1)$ is an important special case known as the standard normal (denoted
$Z$) and has pdf

\begin{equation*}
  \phi(z) = \frac{1}{\sqrt{2\pi}} \; e^{-z^2/2}, \quad -\infty < z < \infty
\end{equation*}

and cdf given by $\Phi(z) = \int_{-\infty}^z \phi(t)\;dt$.\\

Equations 3.3.27, 3.3.29, and 3.3.30, \citet{textbook}.} as an approximation:

\begin{equation}
  F_X(x) \approx \Phi \left( \frac{x + 0.5 - \mu}{\sigma} \right),
\end{equation}

where $\Phi$ is the standard normal cdf and $\mu = np$ and $\sigma =
\sqrt{np(1-p)}$.

This approximation works best when the binomial is perfectly symmetrical, with
$p=0.5$. However as $p$ travels away from 0.5 in either direction, the binomial
becomes increasingly skewed, and one must either provide larger values of $n$
to compensate or face growing inaccuracy. In these cases, the skew-normal
approximation can provide a better alternative.
