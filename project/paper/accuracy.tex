\section{Demonstrating Improved Accuracy}
\label{sec:accuracy}

Now comes the time to justify our efforts by comparing the accuracy of our
skew-normal approximation to that of the normal.

We are naturally most interested in cases where other solutions perform poorly.
Recall that when $n$ is small, it is feasible to execute the binomial
calculations directly, and when $n$ is large or $p$ is close to 0.5, the normal
distribution provides an adequate approximation. Therefore, our interest is
primarily in cases where $n$ is moderate and $p$ is extreme (close to 0 or
1).\footnotemark

\footnotetext{Again, we examine only $p \in (0, 0.5)$. (See footnote
\ref{fnote:half-p-range}.)}

\subsection{Visual Comparison}

The first and most obvious way of judging accuracy is by visual inspection.
Figures \ref{fig:comparison-n25}, \ref{fig:comparison-n50}, and
\ref{fig:comparison-n100} in appendix \ref{app:figures} compare the binomial,
normal, and skew-normal at the small values of $p=0.05$, $p=0.1$, and $p=0.2$
for $n=25$, $n=50$, and $n=100$, respectively.

The graphs in figures \ref{fig:comparison-n25}, \ref{fig:comparison-n50}, and
\ref{fig:comparison-n100} indicate that at moderate $n$ and small $p$, our
skew-normal curve follows the shape of the binomial much more closely than the
normal. As $n$ grows for each value of $p$, however, the Central Limit Theorem
begins to exert its effect and the normal distribution "catches up" in
accuracy, slowly for for more extreme values of $p$ and faster as $p$
approaches 0.5. Thus as we would expect, the skew-normal approximation is of
greatest value when $n$ is moderate and $p$ is extreme.

\subsection{Maximal Absolute Error}
\label{subsec:mabs}

Another more quantitative method of judging accuracy is comparing the maximal
absolute errors of our two approximations, defined by \citet{mabs} as

\begin{equation}
  \textnormal{MABS}(n, p) \eq \max_{k \in \{0, 1,...,n\}} \left| F_{B(n,p)} (k) -  F_{\textnormal{appr}(n,p)}(k + 0.5) \right|
\end{equation}

where $F_{B(n,p)}$ is the cdf of the binomial and $F_{\textnormal{appr}(n,p)}$
is the cdf of either the normal or skew-normal approximation; the 0.5 is a
continuity correction.

Figure \ref{fig:mabs-fixed-n} in appendix \ref{app:figures} shows the MABS of
the skew-normal and the normal approximations as a function of $p$ for $n=25$
and $n=100$. When $p$ is very close to 0, the MABS of the normal approximation
is more than four times that of the skew-normal, again demonstrating the
benefit of using the skew-normal approximation for moderate $n$ and extreme
$p$. The two error curves converge and eventually meet as $p$ approaches 0.5.

Figure \ref{fig:mabs-fixed-p}, on the other hand, shows the MABS of our two
approximations as a function of $n$ for $p=0.05$ and $p=0.1$. At small to
moderate $n$, the normal MABS is roughly six times the skew-normal MABS.
Interestingly, the error curves converge much more slowly this time, leading to
the pleasant (if surprising) conclusion that when $p$ is extreme, the
skew-normal gains us a measure of accuracy even at large $n$.
